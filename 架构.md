
# id全局唯一且自增，如何实现？
Redis的 incr 和 increby 自增原子命令
统一数据库的id发放
美团Leaf
Leaf——美团点评分布式ID生成系统
Twitter的snowflake算法



# 如何设计算法压缩一段URL？
通过发号策略，给每一个过来的长地址，发一个号即可，小型系统直接用mysql的自增索引就搞定了。  
如果是大型应用，可以考虑各种分布式key-value系统做发号器。不停的自增就行了。第一个使用这个  
服务的人得到的短地址是http://xx.xx/0 第二个是 http://xx.xx/1 第11个是 http://xx.xx/a   
第依次往后，相当于实现了一个62进制的自增字段即可。

常用的url压缩算法是短地址映射法。具体步骤是：  

1. 将长网址用md5算法生成32位签名串，分为4段,，每段8个字符；
2. 对这4段循环处理，取每段的8个字符, 将他看成16进制字符串与0x3fffffff(30位1)的位与操作，超过30位的忽略处理；
3. 将每段得到的这30位又分成6段，每5位的数字作为字母表的索引取得特定字符，依次进行获得6位字符串；
4. 这样一个md5字符串可以获得4个6位串，取里面的任意一个就可作为这个长url的短url地址。

# Dubbo负载均衡策略？
随机、轮询、最少使用、一致性哈希（除了一致性哈希外，都有加权）

## 负载均衡算法？

常见6种负载均衡算法：轮询，随机，源地址哈希，加权轮询，加权随机，最小连接数。

nginx5种负载均衡算法：轮询，weight，ip_hash，fair（响应时间），url_hash

dubbo负载均衡算法：随机，轮询，最少活跃调用数，一致性Hash

## Dubbo源码使用了哪些设计模式

A，工厂模式，ExtenstionLoader.getExtenstionLoader(Protocol.class).getAdaptiveExtenstion()

B，装饰器模式+责任链，以provider的调用链为例，具体调用链代码是在protocolFilterWrapper的buildInvokeChain完成的,将注解中含有group=provider的Filter实现，调用顺序为EchoFilter -> ClassLoaderFilter -> GenericFilter -> ContextFilter -> ExceptionFilter -> TimeoutFilter -> MonitorFilter -> TraceFilter。装饰器模式和责任链混合使用，Echo是回声测试请求，ClassLoaderFilter则只是在其主功能上添加了功能。

C，观察者模式，provider启动时需要与注册中心交互，先注册自己的服务，再订阅自己的服务，订阅时采用了观察者模式，注册中心每5s定时检查是否有服务更新，有更新则向服务提供者发送1个notify消息后即可运行NotifyListener的notity方法，执行监听器方法。

D，动态代理模式。  扩展JDK的ExtensionLoaderdeAdaptive实现，根据调用阶段动态参数决定调用哪个类，生成代理类的代码是ExtensionLoader的createAdaptiveExtenstionClassLoader方法。

# Dubbo中Zookeeper做注册中心，如果注册中心集群都挂掉，发布者和订阅者之间还能通信么？
可以，因为dubbo在注册中心挂掉之后，会从原先的缓存中读取连接地址。


# Dubbo完整的一次调用链路介绍？

    调用方：
    1. 将方法名方法参数传入InvokerInvocationHandler的invoke方法中，对于Object中的方法toString, hashCode, equals直接调用invoker的对应方法。
    2. 然后进入（故障转移集群）MockClusterInvoker.invoke()方法中。三种调用策略：①不需要mock， 直接调用FailoverClusterInvoker。②强制mock，调用mock。③先调FailoverClusterInvoker，调用失败在mock.
    3. FailoverClusterInvoker默认调用策略。①通过目录服务查找到所有订阅的服务提供者的Invoker对象。②路由服务根据策略（比如：容错策略）来过滤选择调用的Invokers。③通过负载均衡策略LoadBalance来选择一个Invoker
    4. 执行选择的Invoker.invoker(invocation),经过监听器链，经过过滤器链,执行到远程调用的DubboInvoker。
    5. DubboInvoker根据url 也就是根据服务提供者的长连接，这里封装成交互层对象ExchangeClient供这里调用，判断远程调用类型同步，异步还是oneway模式。ExchangeClient发起远程调用。
    6.获取调用结果：①Oneway返回空RpcResult②异步，直接返回空RpcResult, ResponseFuture回调③同步， ResponseFuture模式同步转异步，等待响应返回

    消费方：
    1.通过Invocation获取服务名和端口组成serviceKey=com.alibaba.dubbo.demo.DemoService:20880, 从DubboProtocol的exproterMap中获取暴露服务的DubboExporter, 在从dubboExporter 获取invoker返回
    2.经过过滤器链。
    3.经过监听器链。
    4.到达执行真正调用的invoker， 这个invoker由代理工厂ProxyFactory.getInvoker(demoService, DemoService.class, registryUrl)创建，具体请看代理那部分介绍。
    5.调用demoService实例方法，将结果封装成RpcResult返回。
    
    
# SpringCloud和Dubbo有什么不一样？
1.dubbo采用RPC的方式交互，SpringCloud采用Http,restful协议进行交互。
2.dubbo依赖zookeeper进行服务注册，Springloud自己拥有自己的服务注册中心。
3.dubbo需要强依赖，需要持有相同的类或者jar包，springcloud弱依赖，但需要通过接口文档进行约束。
4.C数据一致性，A服务可用性，P服务对网络分区故障的容错性，Zookeeper 保证的是CP，
euraka保证的是AP。


# 使用Redis如何实现分布式锁？

redis创建一个订单id，和客户端id，和生存时间。默认一个线程会一直延长这个生存时间。如果其他线程查询到这个值，
并且客户端的id不是自己的话，判断这个锁被别人用了。


# Tomcat如何优化？
虚拟机参数：1.server模式。2.最大堆最小堆大小。3.年轻代和老年代的比例。
4.开启优化。5.使用偏向锁。6.gc年龄。7.合适的gc
tomcat参数：1.maxThread。2.minThread。3.acceptCoun。4.connectionTimeout。6.maxProcessors与minProcessors。


# 后台系统怎么防止请求重复提交？
1.通过数据库订单的状态。（事务的情况）
2.缓存锁定订单号。
3.会话记录请求url
4.申请凭证。


# 后台系统怎么防止请求频繁？
根据用户id，存入一个用户id，和调用次数的值，值的过期时间为2秒。
当超过10的话，提示请求频繁

# 请谈谈单点登录原理？

同域下的单点登录，只需共享session即可。
登录业务系统，跳转至SSO服务器，判断用户名密码正确，在sso域下种下cookie，在session中标记为登录，返回一个ticket，跳转到业务系统，业务系统再拿这个ticket跑去SSO服务器验证ticket是否有效，有效的话，在业务系统session中设置为已登录即可。



相比于单系统登录，sso需要一个独立的认证中心，只有认证中心能接受用户的用户名密码等安全信息，其他系统不提供登录入口，只接受认证中心的间接授权。间接授权通过令牌实现，sso认证中心验证用户的用户名密码没问题，创建授权令牌，在接下来的跳转过程中，授权令牌作为参数发送给各个子系统，子系统拿到令牌，即得到了授权，可以借此创建局部会话，局部会话登录方式与单系统的登录方式相同。这个过程，也就是单点登录的原理，用下图说明



单点登录自然也要单点注销，在一个子系统中注销，所有子系统的会话都将被销毁，用下面的图来说明


# Linux常见命令有哪些？
cd、ls、grep、find、cp、mv、rm、ps、kill、killall、file、tar
cat、chgrp、chown、chmod、vim、gcc、time

# 请说说什么是Maven的依赖、继承以及聚合？
依赖是jar之间的依赖。
聚合是项目中多模块构建。
继承是子模块复用父模块的公共依赖。

# Git暂存区和工作区的区别？

git add命令实际上就是把要提交的所有修改放到暂存区（Stage）
git commit就可以一次性把暂存区的所有修改提交到分支


# Git如何创建、回退以及撤销版本？

git checkout -- filename
git reset --hard HEAD^

# 谈谈项目中分布式事务应用场景？
先理解CAP原理。
①分库分表的情况下
②一个事务涉及到订单的数据库和账户的数据库


## MQ和数据库的一致性问题。
MQ做数据同步也会造成不一致，又需要引入监控，实时计算2个集群的数据同步，做一致性同步。大部分来说，同步es和solr不要在代码中去同步，同步失败无法保证事务，而且业务耦合。可以使用Databug和cancel等工具去做代码解耦，MQ支持重试，存储失败后抛出异常下次再处理。数据做异构，对外服务时任意拼装，MYSQL在半同步复制上做了一些优化，保证了一致性，引入了诸如paxos等主流算法保证强一致性问题。
当DB（监听从库），binlog有变化，cancel监听到时候解析过滤发送MQ（表名字，主键等）到变化的实时从库中查询数据同步到ES聚合表，MQ可以重试，系统解耦。事务log挖掘县城会对DB的事务log监听，并把这些事件发布到消息代理。


## 正在处理的队列突然断电怎么办？

正在处理的实现事务功能，下次自动回滚。
队列实现持久化储存，下次启动自动载入。
添加标志位，未处理 0，处理中 1，已处理 2。每次启动的时候，把所有状态为 1 的，置为 0。
关键性的应用就给电脑配个 UPS。


## 服务限流的方式

    漏桶：水(请求)先进入到漏桶里,漏桶以一定的速度出水(接口有响应速率),当水流入速度过大会直接溢出(访问频率超过接口响应速率),然后就拒绝请求。
    令牌桶算法：系统会按恒定1/QPS时间间隔(如果QPS=100,则间隔是10ms)往桶里加入Token，如果桶已经满了就不再加了.新请求来临时,会各自拿走一个Token,如果没有Token就拒绝服务。
    基于redis实现的限流：假设每分钟访问次数不能超过10次，在Redis中创建一个键，过期60秒，对此服务接口的访问就把键值加1，在60秒内增加到10的时候，禁止访问服务接口。
    计数器，滑动窗口


## 如何设计幂等？

每次扣减库存时加上1个请求流水编号，上层请求扣减库存没拿到结果的话，重新查询1次做重试操作，量不大都是加锁处理。减少锁的时间，牺牲幂等性，扣减为DB下地操作，查询扣减和设置合成1步，中间没有网络请求。利用缓存，通过写log记录操作，异步合并日志及更新，重启时cache失效，读log恢复，避免重复提交，写操作不建议重试快速失败。多个商品同时增减库存，可使用订单号做幂等处理，应用层对单个商品减库存，操作排队，商品消息ID路由在1个应用server处理，读本地缓存，失效再redis，DB采用乐观锁，组提交，1次减库存多个订单的购买量。可将同一个key下库存m分为n组k1......kn，每组数为m/n，扣减依次在各组扣减，减少并发冲突。队列装满后关闭队列进入，然后用户轮训自己是否抢到了异步ajax，用户资源队列固定长度。2个队列，1个销售的资源队列放入redis，有另外1个队列用来装抢购的会员的uid。

红包状态正常，并成功将状态改为“已领取”，且消息发送成功，用户端开始消费该消息，如果消费失败/超时，用MQ做重试做幂等，直到成功，每条消息有唯一编号且保证消息处理成功与去重表的日志同时出现。

热点将hot data拆分，分在不同库和不同表，分散热点Data，减轻DB并发更新热点带来RT升高和应用连接超时。SQL在mysql层加以限制，SQL超时/thradrunning到1定值则拒绝SQL执行，一定时间异步将结果写入DB，nginx对IP做限制，可能误杀。

## RabbitMQ消息堆积怎么处理？

    增加消费者的处理能力(例如优化代码)，或减少发布频率
    单纯升级硬件不是办法，只能起到一时的作用
    考虑使用队列最大长度限制，RabbitMQ 3.1支持
    给消息设置年龄，超时就丢弃
    默认情况下，rabbitmq消费者为单线程串行消费，设置并发消费两个关键属性concurrentConsumers和prefetchCount，concurrentConsumers设置的是对每个listener在初始化的时候设置的并发消费者的个数，prefetchCount是每次一次性从broker里面取的待消费的消息的个数
    建立新的queue，消费者同时订阅新旧queue
    生产者端缓存数据，在mq被消费完后再发送到mq
    打破发送循环条件，设置合适的qos值，当qos值被用光，而新的ack没有被mq接收时，就可以跳出发送循环，去接收新的消息；消费者主动block接收进程，消费者感受到接收消息过快时主动block，利用block和unblock方法调节接收速率，当接收线程被block时，跳出发送循环。
    新建一个topic，partition是原来的10倍；然后写一个临时的分发数据的consumer程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的10倍数量的queue；接着临时征用10倍的机器来部署consumer，每一批consumer消费一个临时queue的数据；等快速消费完积压数据之后，得恢复原先部署架构，重新用原先的consumer机器来消费消息；
    
    
## kafka消息会不会丢失？

Kafka消息发送分同步(sync)、异步(async)两种方式。默认是使用同步方式，可通过producer.type属性进行配置；Kafka保证消息被安全生产，有三个选项分别是0,1,-1。
通过request.required.acks属性进行配置：
0代表：不进行消息接收是否成功的确认(默认值)；
1代表：当Leader副本接收成功后，返回接收成功确认信息；
-1代表：当Leader和Follower副本都接收成功后，返回接收成功确认信息；

    网络异常
    acks设置为0时，不和Kafka集群进行消息接受确认，当网络发生异常等情况时，存在消息丢失的可能；
    客户端异常
    异步发送时，消息并没有直接发送至Kafka集群，而是在Client端按一定规则缓存并批量发送。在这期间，如果客户端发生死机等情况，都会导致消息的丢失；
    缓冲区满了
    异步发送时，Client端缓存的消息超出了缓冲池的大小，也存在消息丢失的可能；
    Leader副本异常
    acks设置为1时，Leader副本接收成功，Kafka集群就返回成功确认信息，而Follower副本可能还在同步。这时Leader副本突然出现异常，新Leader副本(原Follower副本)未能和其保持一致，就会出现消息丢失的情况；

以上就是消息丢失的几种情况，在日常应用中，我们需要结合自身的应用场景来选择不同的配置。
想要更高的吞吐量就设置：异步、ack=0；想要不丢失消息数据就选：同步、ack=-1策略
