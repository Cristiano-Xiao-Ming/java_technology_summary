
# id全局唯一且自增，如何实现？
Redis的 incr 和 increby 自增原子命令
统一数据库的id发放
美团Leaf
Leaf——美团点评分布式ID生成系统
Twitter的snowflake算法



# 如何设计算法压缩一段URL？
通过发号策略，给每一个过来的长地址，发一个号即可，小型系统直接用mysql的自增索引就搞定了。  
如果是大型应用，可以考虑各种分布式key-value系统做发号器。不停的自增就行了。第一个使用这个  
服务的人得到的短地址是http://xx.xx/0 第二个是 http://xx.xx/1 第11个是 http://xx.xx/a   
第依次往后，相当于实现了一个62进制的自增字段即可。

常用的url压缩算法是短地址映射法。具体步骤是：  

1. 将长网址用md5算法生成32位签名串，分为4段,，每段8个字符；
2. 对这4段循环处理，取每段的8个字符, 将他看成16进制字符串与0x3fffffff(30位1)的位与操作，超过30位的忽略处理；
3. 将每段得到的这30位又分成6段，每5位的数字作为字母表的索引取得特定字符，依次进行获得6位字符串；
4. 这样一个md5字符串可以获得4个6位串，取里面的任意一个就可作为这个长url的短url地址。

# Dubbo负载均衡策略？
随机、轮询、最少使用、一致性哈希（除了一致性哈希外，都有加权）

## 负载均衡算法？

常见6种负载均衡算法：轮询，随机，源地址哈希，加权轮询，加权随机，最小连接数。

nginx5种负载均衡算法：轮询，weight，ip_hash，fair（响应时间），url_hash

dubbo负载均衡算法：随机，轮询，最少活跃调用数，一致性Hash


# Dubbo中Zookeeper做注册中心，如果注册中心集群都挂掉，发布者和订阅者之间还能通信么？
可以，因为dubbo在注册中心挂掉之后，会从原先的缓存中读取连接地址。


# Dubbo完整的一次调用链路介绍？

    调用方：
    1. 将方法名方法参数传入InvokerInvocationHandler的invoke方法中，对于Object中的方法toString, hashCode, equals直接调用invoker的对应方法。
    2. 然后进入（故障转移集群）MockClusterInvoker.invoke()方法中。三种调用策略：①不需要mock， 直接调用FailoverClusterInvoker。②强制mock，调用mock。③先调FailoverClusterInvoker，调用失败在mock.
    3. FailoverClusterInvoker默认调用策略。①通过目录服务查找到所有订阅的服务提供者的Invoker对象。②路由服务根据策略（比如：容错策略）来过滤选择调用的Invokers。③通过负载均衡策略LoadBalance来选择一个Invoker
    4. 执行选择的Invoker.invoker(invocation),经过监听器链，经过过滤器链,执行到远程调用的DubboInvoker。
    5. DubboInvoker根据url 也就是根据服务提供者的长连接，这里封装成交互层对象ExchangeClient供这里调用，判断远程调用类型同步，异步还是oneway模式。ExchangeClient发起远程调用。
    6.获取调用结果：①Oneway返回空RpcResult②异步，直接返回空RpcResult, ResponseFuture回调③同步， ResponseFuture模式同步转异步，等待响应返回

    消费方：
    1.通过Invocation获取服务名和端口组成serviceKey=com.alibaba.dubbo.demo.DemoService:20880, 从DubboProtocol的exproterMap中获取暴露服务的DubboExporter, 在从dubboExporter 获取invoker返回
    2.经过过滤器链。
    3.经过监听器链。
    4.到达执行真正调用的invoker， 这个invoker由代理工厂ProxyFactory.getInvoker(demoService, DemoService.class, registryUrl)创建，具体请看代理那部分介绍。
    5.调用demoService实例方法，将结果封装成RpcResult返回。
    
    
# SpringCloud和Dubbo有什么不一样？
1.dubbo采用RPC的方式交互，SpringCloud采用Http,restful协议进行交互。
2.dubbo依赖zookeeper进行服务注册，Springloud自己拥有自己的服务注册中心。
3.dubbo需要强依赖，需要持有相同的类或者jar包，springcloud弱依赖，但需要通过接口文档进行约束。
4.C数据一致性，A服务可用性，P服务对网络分区故障的容错性，Zookeeper 保证的是CP，
euraka保证的是AP。


# 使用Redis如何实现分布式锁？

redis创建一个订单id，和客户端id，和生存时间。默认一个线程会一直延长这个生存时间。如果其他线程查询到这个值，
并且客户端的id不是自己的话，判断这个锁被别人用了。


# Tomcat如何优化？
虚拟机参数：1.server模式。2.最大堆最小堆大小。3.年轻代和老年代的比例。
4.开启优化。5.使用偏向锁。6.gc年龄。7.合适的gc
tomcat参数：1.maxThread。2.minThread。3.acceptCoun。4.connectionTimeout。6.maxProcessors与minProcessors。


# 后台系统怎么防止请求重复提交？
1.通过数据库订单的状态。（事务的情况）
2.缓存锁定订单号。
3.会话记录请求url
4.申请凭证。


# 后台系统怎么防止请求频繁？
根据用户id，存入一个用户id，和调用次数的值，值的过期时间为2秒。
当超过10的话，提示请求频繁

# 请谈谈单点登录原理？

同域下的单点登录，只需共享session即可。
登录业务系统，跳转至SSO服务器，判断用户名密码正确，在sso域下种下cookie，在session中标记为登录，返回一个ticket，跳转到业务系统，业务系统再拿这个ticket跑去SSO服务器验证ticket是否有效，有效的话，在业务系统session中设置为已登录即可。



相比于单系统登录，sso需要一个独立的认证中心，只有认证中心能接受用户的用户名密码等安全信息，其他系统不提供登录入口，只接受认证中心的间接授权。间接授权通过令牌实现，sso认证中心验证用户的用户名密码没问题，创建授权令牌，在接下来的跳转过程中，授权令牌作为参数发送给各个子系统，子系统拿到令牌，即得到了授权，可以借此创建局部会话，局部会话登录方式与单系统的登录方式相同。这个过程，也就是单点登录的原理，用下图说明



单点登录自然也要单点注销，在一个子系统中注销，所有子系统的会话都将被销毁，用下面的图来说明


# Linux常见命令有哪些？
cd、ls、grep、find、cp、mv、rm、ps、kill、killall、file、tar
cat、chgrp、chown、chmod、vim、gcc、time

# 请说说什么是Maven的依赖、继承以及聚合？
依赖是jar之间的依赖。
聚合是项目中多模块构建。
继承是子模块复用父模块的公共依赖。

# Git暂存区和工作区的区别？

git add命令实际上就是把要提交的所有修改放到暂存区（Stage）
git commit就可以一次性把暂存区的所有修改提交到分支


# Git如何创建、回退以及撤销版本？

git checkout -- filename
git reset --hard HEAD^

# 谈谈项目中分布式事务应用场景？
先理解CAP原理。
①分库分表的情况下
②一个事务涉及到订单的数据库和账户的数据库


## MQ和数据库的一致性问题。
MQ做数据同步也会造成不一致，又需要引入监控，实时计算2个集群的数据同步，做一致性同步。大部分来说，同步es和solr不要在代码中去同步，同步失败无法保证事务，而且业务耦合。可以使用Databug和cancel等工具去做代码解耦，MQ支持重试，存储失败后抛出异常下次再处理。数据做异构，对外服务时任意拼装，MYSQL在半同步复制上做了一些优化，保证了一致性，引入了诸如paxos等主流算法保证强一致性问题。
当DB（监听从库），binlog有变化，cancel监听到时候解析过滤发送MQ（表名字，主键等）到变化的实时从库中查询数据同步到ES聚合表，MQ可以重试，系统解耦。事务log挖掘县城会对DB的事务log监听，并把这些事件发布到消息代理。


## 正在处理的队列突然断电怎么办？

正在处理的实现事务功能，下次自动回滚。
队列实现持久化储存，下次启动自动载入。
添加标志位，未处理 0，处理中 1，已处理 2。每次启动的时候，把所有状态为 1 的，置为 0。
关键性的应用就给电脑配个 UPS。


## 服务限流的方式

    漏桶：水(请求)先进入到漏桶里,漏桶以一定的速度出水(接口有响应速率),当水流入速度过大会直接溢出(访问频率超过接口响应速率),然后就拒绝请求。
    令牌桶算法：系统会按恒定1/QPS时间间隔(如果QPS=100,则间隔是10ms)往桶里加入Token，如果桶已经满了就不再加了.新请求来临时,会各自拿走一个Token,如果没有Token就拒绝服务。
    基于redis实现的限流：假设每分钟访问次数不能超过10次，在Redis中创建一个键，过期60秒，对此服务接口的访问就把键值加1，在60秒内增加到10的时候，禁止访问服务接口。
    计数器，滑动窗口


## 如何设计幂等？

每次扣减库存时加上1个请求流水编号，上层请求扣减库存没拿到结果的话，重新查询1次做重试操作，量不大都是加锁处理。减少锁的时间，牺牲幂等性，扣减为DB下地操作，查询扣减和设置合成1步，中间没有网络请求。利用缓存，通过写log记录操作，异步合并日志及更新，重启时cache失效，读log恢复，避免重复提交，写操作不建议重试快速失败。多个商品同时增减库存，可使用订单号做幂等处理，应用层对单个商品减库存，操作排队，商品消息ID路由在1个应用server处理，读本地缓存，失效再redis，DB采用乐观锁，组提交，1次减库存多个订单的购买量。可将同一个key下库存m分为n组k1......kn，每组数为m/n，扣减依次在各组扣减，减少并发冲突。队列装满后关闭队列进入，然后用户轮训自己是否抢到了异步ajax，用户资源队列固定长度。2个队列，1个销售的资源队列放入redis，有另外1个队列用来装抢购的会员的uid。

红包状态正常，并成功将状态改为“已领取”，且消息发送成功，用户端开始消费该消息，如果消费失败/超时，用MQ做重试做幂等，直到成功，每条消息有唯一编号且保证消息处理成功与去重表的日志同时出现。

热点将hot data拆分，分在不同库和不同表，分散热点Data，减轻DB并发更新热点带来RT升高和应用连接超时。SQL在mysql层加以限制，SQL超时/thradrunning到1定值则拒绝SQL执行，一定时间异步将结果写入DB，nginx对IP做限制，可能误杀。

## RabbitMQ消息堆积怎么处理？

    增加消费者的处理能力(例如优化代码)，或减少发布频率
    单纯升级硬件不是办法，只能起到一时的作用
    考虑使用队列最大长度限制，RabbitMQ 3.1支持
    给消息设置年龄，超时就丢弃
    默认情况下，rabbitmq消费者为单线程串行消费，设置并发消费两个关键属性concurrentConsumers和prefetchCount，concurrentConsumers设置的是对每个listener在初始化的时候设置的并发消费者的个数，prefetchCount是每次一次性从broker里面取的待消费的消息的个数
    建立新的queue，消费者同时订阅新旧queue
    生产者端缓存数据，在mq被消费完后再发送到mq
    打破发送循环条件，设置合适的qos值，当qos值被用光，而新的ack没有被mq接收时，就可以跳出发送循环，去接收新的消息；消费者主动block接收进程，消费者感受到接收消息过快时主动block，利用block和unblock方法调节接收速率，当接收线程被block时，跳出发送循环。
    新建一个topic，partition是原来的10倍；然后写一个临时的分发数据的consumer程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的10倍数量的queue；接着临时征用10倍的机器来部署consumer，每一批consumer消费一个临时queue的数据；等快速消费完积压数据之后，得恢复原先部署架构，重新用原先的consumer机器来消费消息；
    
    
## kafka消息会不会丢失？

Kafka消息发送分同步(sync)、异步(async)两种方式。默认是使用同步方式，可通过producer.type属性进行配置；Kafka保证消息被安全生产，有三个选项分别是0,1,-1。
通过request.required.acks属性进行配置：
0代表：不进行消息接收是否成功的确认(默认值)；
1代表：当Leader副本接收成功后，返回接收成功确认信息；
-1代表：当Leader和Follower副本都接收成功后，返回接收成功确认信息；

    网络异常
    acks设置为0时，不和Kafka集群进行消息接受确认，当网络发生异常等情况时，存在消息丢失的可能；
    客户端异常
    异步发送时，消息并没有直接发送至Kafka集群，而是在Client端按一定规则缓存并批量发送。在这期间，如果客户端发生死机等情况，都会导致消息的丢失；
    缓冲区满了
    异步发送时，Client端缓存的消息超出了缓冲池的大小，也存在消息丢失的可能；
    Leader副本异常
    acks设置为1时，Leader副本接收成功，Kafka集群就返回成功确认信息，而Follower副本可能还在同步。这时Leader副本突然出现异常，新Leader副本(原Follower副本)未能和其保持一致，就会出现消息丢失的情况；

以上就是消息丢失的几种情况，在日常应用中，我们需要结合自身的应用场景来选择不同的配置。
想要更高的吞吐量就设置：异步、ack=0；想要不丢失消息数据就选：同步、ack=-1策略


## RabbitMQ的消息丢失解决方案？

    消息持久化：Exchange 设置持久化：durable:true；Queue 设置持久化；Message持久化发送。
    ACK确认机制：消息发送确认；消息接收确认。
    
## kafka的leader副本选举？

如果某个分区patition的Leader挂了,那么其它跟随者将会进行选举产生一个新的leader,之后所有的读写就会转移到这个新的Leader上,在kafka中,其不是采用常见的多数选举的方式进行副本的Leader选举,而是会在Zookeeper上针对每个Topic维护一个称为ISR（in-sync replica，已同步的副本）的集合,显然还有一些副本没有来得及同步。只有这个ISR列表里面的才有资格成为leader(先使用ISR里面的第一个，如果不行依次类推，因为ISR里面的是同步副本，消息是最完整且各个节点都是一样的)。
  通过ISR,kafka需要的冗余度较低，可以容忍的失败数比较高。假设某个topic有f+1个副本，kafka可以容忍f个不可用,当然,如果全部ISR里面的副本都不可用,也可以选择其他可用的副本,只是存在数据的不一致。
  
  
## kafka消息的检索？

其实很简单主要是用二分查找算法,比如我们要查找一条offest=10000的文件,kafka首先会在对应分区下的log文件里采用二分查看定位到某个记录该offest
=10000这条消息的log,然后从相应的index文件定位其偏移量,然后拿着偏移量到log里面直接获取。这样就完成了一个消息的检索过程。


## RabbitMQ 集群方式？

1）普通集群：

以两个节点（rabbit01、rabbit02）为例来进行说明。
    rabbit01和rabbit02两个节点仅有相同的元数据，即队列的结构，但消息实体只存在于其中一个节点rabbit01（或者rabbit02）中。
    当消息进入rabbit01节点的Queue后，consumer从rabbit02节点消费时，RabbitMQ会临时在rabbit01、rabbit02间进行消息传输，把A中的消息实体取出并经过B发送给consumer。所以consumer应尽量连接每一个节点，从中取消息。即对于同一个逻辑队列，要在多个节点建立物理Queue。否则无论consumer连rabbit01或rabbit02，出口总在rabbit01，会产生瓶颈。当rabbit01节点故障后，rabbit02节点无法取到rabbit01节点中还未消费的消息实体。如果做了消息持久化，那么得等rabbit01节点恢复，然后才可被消费；如果没有持久化的话，就会产生消息丢失的现象。

2）镜像集群：

 在普通集群的基础上，把需要的队列做成镜像队列，消息实体会主动在镜像节点间同步，而不是在客户端取数据时临时拉取，也就是说多少节点消息就会备份多少份。该模式带来的副作用也很明显，除了降低系统性能外，如果镜像队列数量过多，加之大量的消息进入，集群内部的网络带宽将会被这种同步通讯大大消耗掉。所以在对可靠性要求较高的场合中适用
    由于镜像队列之间消息自动同步，且内部有选举master机制，即使master节点宕机也不会影响整个集群的使用，达到去中心化的目的，从而有效的防止消息丢失及服务不可用等问题
    
## kafka高性能的原因？

A，Broker NIO异步消息处理，实现了IO线程与业务线程分离；

B，磁盘顺序写；

C， 零拷贝（跳过用户缓冲区的拷贝，建立一个磁盘空间和内存的直接映射，数据不再复制到用户态缓冲区）；

D，分区/分段（每次文件操作都是对一个小文件的操作，非常轻便，同时也增加了并行处理能力）；

F，批量发送 (可以指定缓存的消息达到某个量的时候就发出去，或者缓存了固定的时间后就发送出去，大大减少服务端的I/O次数)

E，数据压缩


## ZooKeeper分布式高可用

ZooKeeper 运行期间，集群中至少有过半的机器保存了最新数据。集群超过半数的机器能够正常工作，集群就能够对外提供服务。

zookeeper可以选出N台机器作主机，它可以实现M:N的备份；keepalive只能选出1台机器作主机，所以keepalive只能实现M:1的备份。

通常有以下两种部署方案：双机房部署（一个稳定性更好、设备更可靠的机房，这个机房就是主要机房，而另外一个机房则更加廉价一些，例如，对于一个由 7 台机器组成的 ZooKeeper 集群，通常在主要机房中部署 4 台机器，剩下的 3 台机器部署到另外一个机房中）；三机房部署（无论哪个机房发生了故障，剩下两个机房的机器数量都超过半数。在三个机房中都部署若干个机器来组成一个 ZooKeeper 集群。假设机器总数为 N，各机房机器数：N1 = (N-1)/2 ，N2=1~(N-N1)/2 ，N3 = N - N1 - N2 ）。

水平扩容就是向集群中添加更多机器，Zookeeper2种方式（不完美），一种是集群整体重启，另外一种是逐台进行服务器的重启。






## 幂等的处理方式？

答：一、查询与删除操作是天然幂等

二、唯一索引，防止新增脏数据

三、token机制，防止页面重复提交

四、悲观锁  for update

五、乐观锁（通过版本号/时间戳实现， 通过条件限制where avai_amount-#subAmount# >= 0）

六、分布式锁

七、状态机幂等（如果状态机已经处于下一个状态，这时候来了一个上一个状态的变更，理论上是不能够变更的，这样的话，保证了有限状态机的幂等。）

八、select + insert（并发不高的后台系统，或者一些任务JOB，为了支持幂等，支持重复执行）


## 如何设计秒杀

异步化，生产接口每秒钟10万并发，消费者用异步慢慢消费。缓存模式空间换时间，把1两亿的数据名单打到缓存。服务降级，把不重要的任务放弃；静态资源离线包下载机制，在wify下会主动提前把静态下载前端层保护可请将用户请求延长，点击后主动给它随机等待2s的时间/2分钟之内不能请求；后端做部分接口的开关，设置超短耗时时间，原来只用5ms的只给20ms。

系统一段时间内会自动重试，重试多次后就认为是失败了，检查支付接口返回该订单的钱，支付操作如果回复错误则回滚扣库存的事务，没返回则会记录进行中pendding状态，结束整个过程，等通知失败/成功，AB系统之间会出现死循环补偿，如B退单不成功，一般就是记录错误日志了。超时每隔一段时间去定时回调服务定时回滚，一定次数还是超时则提示用户联系客服，订单库存可以不会滚，记录状态，如果一直调用支付不成功，则让用户自己去处理联系客服，可以不回滚用户的数据，金额扣了才算真正完成，是一种简单粗暴的做法。

公共配置抽象成存储到zookeeper配置中心或者redis等，DB也存储一份，各应用监听ZK的配置变化，可以建一个配置web管理页面。


## 高性能统计UV的方式？

（1）使用redis的set集合

（2）使用redis的bitmap（注意内存消耗）


## 缓存击透

预加载；

加载DB时同步，其他则等待；

DB端做SQL合并，Queue合并排队处理；

部分缓存设置为永不过期；

先清除缓存，读取数据时候则等待500ms，500ms缓存应该已经加载完成；

采用双key缓存，A1为原始缓存，A2为拷贝缓存；

如果DB为空null则g给redis设置1个NFC空nei容。




## 后台系统怎么防止请求重复提交。
前端js，控制按钮。前端放置令牌。
数据库唯一索引。redis看key是否存在。或者数据库字段状态。

## 如何做限流策略，令牌桶和漏斗算法的使用场景。
    令牌桶可以应对突发的大流量
   漏斗算法用于请求恒定速率通过


## 有没有遇到进线上GC，出现的症状是什么样的，怎么解决的？
利用堆快照，查看到底是哪些对象占用大量内存导致经常gc


## 假如你的项目出现性能瓶颈了，你觉得可能会是哪些方面，怎么解决问题。
DB层面，有可能是sql，索引，表过大。
缓存层面：有可能缓存命中率差
Java层面:代码写法
架构层面：服务器不够

## 情景题：如果一个外卖配送单子要发布，现在有200个骑手都想要接这一单，如何保证只有一个骑手接到单子？
分布式锁，或者幂等接口，CAS乐观锁

## 场景题：美团首页每天会从10000个商家里面推荐50个商家置顶，每个商家有一个权值，你如何来推荐？第二天怎么更新推荐的商家？
可以借鉴下stackoverflow，视频网站等等的推荐算法。


## 场景题：微信抢红包问题
悲观锁，乐观锁，存储过程放在mysql数据库中。


## 场景题：1000个任务，分给10个人做，你怎么分配，先在纸上写个最简单的版本，然后优化。
全局队列，把1000任务放在一个队列里面，然后每个人都是取，完成任务。
分为10个队列，每个人分别到自己对应的队列中去取务。

